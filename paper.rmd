---
title: "IST 782 Applied Portfolio"
author: "Francisco Franco Arenas"
output:
  pdf_document: 
    toc: true
    toc_depth: 3
  word_document: default
abstract: "This paper serves as a comprehensive demonstration of how I have met the program’s learning goals through various assignments and project deliverables. Each section of this document links specific learning objectives to the practical work I have completed, showcasing not only my academic achievements but also my preparedness for a career in data science. By examining the projects I have undertaken, the methodologies I have employed, and the insights I have generated, this paper provides a holistic view of my growth as a data scientist and my readiness to tackle real-world challenges."
---


\newpage


# 1. introduction

Data science stands at the intersection of statistical analysis, computational techniques, and domain-specific knowledge, offering powerful tools for extracting meaningful insights from vast datasets. As an economist at the Ministry of Economic Affairs in Spain, I recognized the transformative potential of data science to enhance decision-making and policy formulation. Pursuing a Master of Science in Applied Data Science was a strategic decision to augment my expertise with advanced data analysis skills. This program has equipped me with the ability to harness complex data, apply sophisticated machine learning algorithms, and develop predictive models, thereby improving my capacity to analyze economic trends, evaluate policies, and make data-driven recommendations. The integration of these skills is crucial in today’s data-driven world, enabling me to contribute more effectively to the mission of fostering economic stability and growth.

As I reflect on my journey through the Master of Science in Applied Data Science program at Syracuse University, this paper serves as a comprehensive demonstration of how I have met the program’s learning goals through various assignments and project deliverables. Each section of this document links specific learning objectives to the practical work I have completed, showcasing not only my academic achievements but also my preparedness for a career in data science. By examining the projects I have undertaken, the methodologies I have employed, and the insights I have generated, this paper provides a holistic view of my growth as a data scientist and my readiness to tackle real-world challenges.


# 2. Learning goals

The main learning goals of the program are as follows:

1. Collect, store, and access data by identifying and leveraging applicable technologies
2. Create actionable insight across a range of contexts (e.g. societal, business, political), using data and the full data science life cycle
3. Apply visualization and predictive models to help generate actionable insight
4. Use programming languages such as R and Python to support the generation of actionable insight
5. Communicate insights gained via visualization and analytics to a broad range of audiences (including project sponsors and technical team leads)
6. Apply ethics in the development, use and evaluation of data and predictive models (e.g., fairness, bias, transparency, privacy)


\newpage

# 3. Projects
## 3.1 Project 1: IST 719 Information Visualization: Poster on transitions from University to employment in Spain

Associated learning goals: 1,2,3,4,5

### Description

In the IST 719 Information Visualization course, we explored advanced visualization techniques, primarily utilizing R's ggplot2 library, while grounding our practice in the theoretical principles of effective data visualization. The course also introduced us to Adobe Illustrator, enabling us to design visually compelling posters that effectively communicate complex data insights.

For my project, I developed an in-depth poster using data from the University Placement Survey of Spain. This project aimed to evaluate the effectiveness of various fields of study in facilitating the transition from university to employment. It provided a comprehensive analysis of how different academic disciplines prepare students for the job market. Through this project, I gained significant experience in handling and transforming public survey data into meaningful and impactful visual representations.

The first step in the proh¡ject was to  obtain a suitable dataset where interesting insights could be extracted. The University Placement Survey of Spain was chosen due to its rich information on graduates' employment outcomes, including fields of study, employment sectors, and wages. The dataset was cleaned and transformed to extract relevant variables for analysis, such as employment rates, average wages, and career pathways.

The poster featured several advanced visualization techniques that extended beyond the standard curriculum. I created an alluvial plot to illustrate the flow of graduates into various employment sectors, capturing the pathways from education to career. Ridgeline plots were employed to compare wages across different fields of study, offering a clear and concise overview of which disciplines have the highest and lowest wages. Additionally, Cleveland dot plots were used to highlight key statistics, providing a straightforward comparison of employment outcomes for graduates in different fields.The ideas for the advanced plots came from exploring different websites that show examples of advanced plots^[www.data-to-viz.com].

This project was a crucial learning experience that honed my technical skills in data visualization and my ability to convey complex information effectively. It underscored the importance of clear and impactful visual communication in the field of data science, particularly in making data-driven insights accessible and understandable to a broader audience. Through this project, I not only applied the skills learned in class but also expanded my proficiency in creating advanced and informative visualizations, which are essential for data-driven decision-making in my role as an economist at the Ministry of Economic Affairs in Spain.

### Demonstrated achievements in learning goals:
**1. Collect, store, and access data by identifying and leveraging applicable technologies:**

   - Obtained and cleaned the University Placement Survey of Spain dataset to extract relevant variables for analysis.
   - Utilized R and ggplot2 to create advanced visualizations that effectively communicated insights from the dataset.
   
**2. Create actionable insight across a range of contexts using data and the full data science life cycle:**

   - Analyzed the effectiveness of different fields of study in facilitating the transition from university to employment.
   - Developed a comprehensive poster that provided actionable insights for students, educators, and policymakers.
   
**3. Apply visualization and predictive models to help generate actionable insight:**

   - Employed advanced visualization techniques such as alluvial plots, ridgeline plots, and Cleveland dot plots to generate actionable insights.
   - Visualized the flow of graduates into employment sectors, compared wages across fields of study, and highlighted key statistics for informed decision-making.
   
**4. Use programming languages such as R and Python to support the generation of actionable insight:**

   - Utilized R and ggplot2 to create advanced visualizations that supported the generation of actionable insights from the dataset.
   - Demonstrated proficiency in R to analyze and visualize data effectively.
   
**5. Communicate insights gained via visualization and analytics to a broad range of audiences:**

   - Designed a visually compelling poster that effectively communicated complex data insights to a broad audience.
   - Presented data-driven insights in a clear and accessible manner, making them understandable to students, educators, and policymakers.

\newpage

## 3.2 Project 2: IST 718 Big Data: ML classifier of financial complaints

Associated learning goals: 1,2,3,4,6

### Description

In the IST 718 Big Data course, we focused on handling large datasets using Apache Spark. We began by delving into the theory behind the MapReduce architecture to understand Spark's underlying mechanisms. Subsequently, we learned data wrangling and machine learning techniques within the Spark framework. A crucial aspect of this learning process was grasping Spark's lazy evaluation, which enabled us to program more efficiently by understanding how Spark executes code. The course culminated in a final project where we applied our knowledge of Spark to a real-world big data problem.

For our project, we utilized an open dataset of financial complaints with the objective of classifying them into categories based on the textual content of the complaints. This dataset comprised over 10 million instances, necessitating the application of efficient big data techniques. We employed Spark's MLlib library to preprocess the text data, extract features, and train a multi-class classifier to categorize the complaints accurately. This project provided a hands-on experience in implementing machine learning algorithms on large datasets and addressing challenges such as class imbalance and feature extraction.

To achieve accurate classification, we experimented with various types of text embeddings, ranging from the simpler TF-IDF (Term Frequency-Inverse Document Frequency) to more sophisticated BERT embeddings. Handling the class imbalance within the data was a significant challenge, as the main category encompassed over 50% of the instances. To address this, we implemented a two-stage classifier. The first stage predicted the main category, and for the instances that did not belong to this category, the second stage fine-tuned the classification for the remaining categories. 

This approach not only improved the accuracy of our classification but also ensured that the model was robust across all categories. The final model achieved a total F1 score of 0.763, reflecting its ability to distinguish between different categories effectively. This project was instrumental in enhancing our skills in managing big data, implementing machine learning algorithms on large datasets, and addressing challenges such as class imbalance. These skills are invaluable in my role as an economist, enabling me to analyze large-scale financial data and derive meaningful insights for informed decision-making. 

### Demonstrated achievements in learning goals:
**1. Collect, store, and access data by identifying and leveraging applicable technologies:**

   - Utilized the souce API to obtain the financial complaints dataset.
   - Employed Apache Spark to handle and process the large dataset efficiently.

**2. Create actionable insight across a range of contexts using data and the full data science life cycle:**

   - Classified financial complaints into categories based on textual content, providing actionable insights for financial institutions.
   - Developed a multi-class classifier that accurately categorized complaints, enabling informed decision-making.
   
**3. Apply visualization and predictive models to help generate actionable insight:**

   - Utilized Spark's MLlib library to preprocess text data, extract features, and train a multi-class classifier.
   - Experimented with different text embeddings and implemented a two-stage classifier to address class imbalance and improve classification accuracy.

**4. Use programming languages such as R and Python to support the generation of actionable insight:**

   - Employed pySpark to preprocess and classify the financial complaints dataset.
   - Demonstrated proficiency in Spark's MLlib library to implement machine learning algorithms on large datasets effectively.
   
**6. Apply ethics in the development, use and evaluation of data and predictive models:**

   - Ensured fairness and transparency in the classification process by addressing class imbalance and implementing a two-stage classifier.
   - Considered ethical implications in the development and evaluation of the predictive model to ensure unbiased and accurate classification of financial complaints.

\newpage

## 3.3 Project 3: IST 737 Visual Analytic Dashboards: Europe's quality of life visualization dashboard

Associated learning goals: 1,2,3,4,5

### Description

In the IST 737 Visual Analytic Dashboards course, I focused on creating interactive visual analytic dashboards using Tableau. We started with the basics and advanced to complex topics such as window functions. The course emphasized not only creating visualizations but also communicating stories effectively through interactive data.

For my project, I developed an interactive dashboard that visualizes the quality of life in the European Union. The goal was to provide a comprehensive and interactive tool for exploring various aspects of quality of life across EU countries. The project involved collecting data from Eurostat, the statistical office of the European Union, and transforming it into a format suitable for visualization in Tableau. This project allowed me to leverage my skills in data collection, data preparation, and data visualization to create an engaging and informative dashboard.

The project began with the creation of a data pipeline to automatically ingest data from Eurostat using the Eurostat API. This required a deep understanding of API integration and data extraction techniques. Once the data was ingested, I prepared it for Tableau by ensuring it was efficiently modeled for optimal performance. This involved cleaning and transforming the data to ensure it was in the correct format and structure for analysis.

The dashboard focused on three main topics: health, job quality, and life satisfaction. Each topic was explored through multiple interconnected dashboards:

   - Health: I created visualizations to display metrics such as healthcare resources, good habits and prevalence of various health conditions. Interactive elements allowed users to compare health outcomes across different countries and demographic groups.

   - Job Quality: This section highlighted data on job satisfaction, job security, and working conditions. Visualizations included comparative bar charts, heatmaps, and trend lines to show how job quality varied across the EU.

  -  Life Satisfaction: I used surveys and subjective well-being data to create visualizations that depicted overall life satisfaction. This included mapping satisfaction scores across regions and demographic segments, using color-coded maps and dynamic charts.

Through these dashboards, I aimed to tell a compelling story that went beyond the raw data, providing context and insights into the quality of life in the EU. The interactive nature of the dashboard allowed users to explore the data in a meaningful way, revealing patterns and trends that are not immediately apparent in static reports. 

This project significantly enhanced my expertise in Tableau, allowing me to leverage its powerful features to create engaging and informative visualizations. However, I have encountered some difficulties in transferring these skills to PowerBI, the software used in my current job. Despite this challenge, the project has been invaluable in developing my ability to create meaningful and interactive data presentations, a crucial skill for my role as an economist at the Ministry of Economic Affairs in Spain. 

### Demonstrated achievements in learning goals:
**1. Collect, store, and access data by identifying and leveraging applicable technologies:**

   - Developed a data pipeline to automatically ingest data from Eurostat using the Eurostat API.
   - Prepared data for Tableau by cleaning and transforming it to ensure optimal performance.

**2. Create actionable insight across a range of contexts using data and the full data science life cycle:**

   - Developed an interactive dashboard that visualized the quality of life in the European Union, providing actionable insights for policymakers and researchers.
   - Explored multiple aspects of quality of life, including health, job quality, and life satisfaction, through interconnected dashboards.
   
**3. Apply visualization and predictive models to help generate actionable insight:**

   - Created visualizations to display metrics related to health, job quality, and life satisfaction in the EU.
   - Developed interactive elements that allowed users to explore and compare data across different countries and demographic groups.

**4. Use programming languages such as R and Python to support the generation of actionable insight:**

   - Utilized Tableau to create interactive visual analytic dashboards that effectively communicated insights from the Eurostat data.
   - Demonstrated proficiency in Tableau to develop engaging and informative visualizations that provided actionable insights for policymakers and researchers.
   
**5. Communicate insights gained via visualization and analytics to a broad range of audiences:**

   - Developed an interactive dashboard that effectively communicated the quality of life in the European Union to a broad audience.
   - Created visualizations that told a compelling story and allowed users to explore data in a meaningful way, revealing patterns and trends that are not immediately apparent in static reports.

\newpage

# 4. Conclusion

The Master of Science in Applied Data Science program at Syracuse University has been instrumental in equipping me with the skills and knowledge necessary to excel in the field of data science. Through a combination of theoretical coursework, practical projects, and hands-on experience, I have developed a robust foundation in data analysis, machine learning, and data visualization. The projects presented in this paper demonstrate my proficiency in collecting, analyzing, and visualizing data to generate actionable insights across a range of contexts. By applying programming languages such as R and Python, I have been able to support the development of predictive models and communicate insights effectively to diverse audiences. Moreover, I have consistently applied ethical considerations in the development, use, and evaluation of data and predictive models, ensuring fairness, transparency, and privacy in my work. These projects have not only showcased my academic achievements but also highlighted my readiness to tackle real-world challenges in data science.
